version: '3.8'

services:
  neo4j:
    image: neo4j:5.16-community
    container_name: kg-builder-neo4j
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/your_password_here
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_memory_heap_initial__size=512M
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_memory_pagecache_size=512M
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "your_password_here", "RETURN 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: kg-builder-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Ollama (Optional - uncomment if you want to run Ollama in Docker)
  # Note: For GPU support, see docker-compose.ollama.yml
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: kg-builder-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   # Uncomment for NVIDIA GPU support
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]

  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: kg-builder-api
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=your_password_here
      - REDIS_URL=redis://redis:6379/0
      # Use host Ollama by default (recommended - faster, more flexible)
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      # Or use containerized Ollama (see docker-compose.ollama.yml)
      # - OLLAMA_BASE_URL=http://ollama:11434
    env_file:
      - ../.env
    volumes:
      - ../data:/app/data
      - ../logs:/app/logs
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn kg_builder.api.main:app --host 0.0.0.0 --port 8000 --reload

  celery-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: kg-builder-celery
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=your_password_here
      - REDIS_URL=redis://redis:6379/0
      # Use host Ollama by default (recommended - faster, more flexible)
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      # Or use containerized Ollama (see docker-compose.ollama.yml)
      # - OLLAMA_BASE_URL=http://ollama:11434
    env_file:
      - ../.env
    volumes:
      - ../data:/app/data
      - ../logs:/app/logs
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: celery -A kg_builder.tasks.worker worker --loglevel=info

volumes:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  redis_data:
  # ollama_data:  # Uncomment if using Ollama service
